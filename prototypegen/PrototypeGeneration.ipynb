{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN\n",
    "### (Implementação usada na lista 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean(ai, bi):\n",
    "    return ((float(ai) - float(bi)))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcDistance(query, instance, weighted):\n",
    "    distance = 0\n",
    "    weight = 1\n",
    "    for i in range(len(instance)-1):\n",
    "        distance = distance + euclidean(query[i],instance[i])\n",
    "    distance = (distance)**0.5\n",
    "    if (weighted == 1):\n",
    "        if (distance==0):\n",
    "            distance = 0.01\n",
    "        weight = 1/(distance**2)\n",
    "    return ((distance, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vdm(ai, bi, attributeCount, pos, classList):\n",
    "    nia = 0\n",
    "    nib = 0\n",
    "    vdmResult = 0\n",
    "    for i in range(len(attributeCount)):\n",
    "        if (attributeCount[i][0] == ai and attributeCount[i][2] == pos):\n",
    "            nia = nia + attributeCount[i][3]\n",
    "        if (attributeCount[i][0] == bi and attributeCount[i][2] == pos):\n",
    "            nib = nib + attributeCount[i][3]\n",
    "                   \n",
    "    for j in range(len(classList)):\n",
    "        niac = 0\n",
    "        nibc = 0\n",
    "        for i in range(len(attributeCount)):\n",
    "            if (attributeCount[i][0] == ai and attributeCount[i][1] == classList[j] and attributeCount[i][2] == pos):\n",
    "                niac = niac + attributeCount[i][3]\n",
    "            if (attributeCount[i][0] == ai and attributeCount[i][1] == classList[j] and attributeCount[i][2] == pos):\n",
    "                nibc = nibc + attributeCount[i][3]\n",
    "        \n",
    "        if (nia == 0):\n",
    "            v1 = 0\n",
    "        else:\n",
    "            v1 = niac/nia\n",
    "        \n",
    "        if (nib == 0):\n",
    "            v2 = 0\n",
    "        else:\n",
    "            v2 = nibc/nib\n",
    "        \n",
    "        calc = abs(v1-v2)\n",
    "        vdmResult = vdmResult + calc\n",
    "        \n",
    "    return vdmResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcVDM(query, instance, weighted, attributeCount, classList):\n",
    "    distance = 0\n",
    "    weight = 1\n",
    "    for i in range(len(query)):\n",
    "        distance = distance + vdm(query[i], instance[i], attributeCount, i, classList)\n",
    "    \n",
    "    distance = (distance)**0.5\n",
    "    \n",
    "    if (weighted == 1):\n",
    "        if (distance==0):\n",
    "            distance = 0.01\n",
    "        weight = 1/(distance**2)\n",
    "    \n",
    "    return ((distance, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcHVDM(query, instance, weighted, attributeCount, classList, typeList):\n",
    "    distance = 0\n",
    "    weight = 1\n",
    "    for i in range(len(query)):\n",
    "        if (typeList[i] == 'num'):\n",
    "            distance = distance + ((euclidean(query[i], instance[i]))**2)\n",
    "        elif (typeList[i] == 'cat'):\n",
    "            distance = distance + ((vdm(query[i], instance[i], attributeCount, i, classList))**2)\n",
    "    \n",
    "    distance = (distance)**0.5\n",
    "    \n",
    "    if (weighted == 1):\n",
    "        if(distance==0):\n",
    "            distance = 0.01\n",
    "        weight = 1/(distance**2)\n",
    "    \n",
    "    return ((distance, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNeighbors(distances, n):\n",
    "    classes = []\n",
    "    classList = []\n",
    "    for i in range(n):\n",
    "        myClass = distances[i][0][-1]\n",
    "        myWeight = distances[i][2]\n",
    "        if (myClass not in classList):\n",
    "            classes.append((myClass, myWeight))\n",
    "            classList.append(myClass)\n",
    "        else:\n",
    "            for j in range(len(classes)):\n",
    "                if (myClass == classes[j][0]):\n",
    "                    classes[j] = list(classes[j])\n",
    "                    classes[j][1] = classes[j][1] + myWeight\n",
    "                    break\n",
    "    \n",
    "    classes.sort(key=lambda x: x[1], reverse=True)\n",
    "    return classes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn (query, data, weighted, dataType, typeList):\n",
    "    # k = testInstance\n",
    "    # \n",
    "    #dataType 0 = numérico, 1 = categorico, 2 = heterogeneo\n",
    "    distances = []\n",
    "    classes = []\n",
    "    \n",
    "    attributeCount = []\n",
    "    \n",
    "    classColumn = [row[-1] for row in data]\n",
    "    classList = []\n",
    "    \n",
    "    for i in range(len(classColumn)):\n",
    "        if (classColumn[i] not in classList):\n",
    "            classList.append(classColumn[i])\n",
    "    \n",
    "    for i in range(len(data[0])-1):\n",
    "        for j in range(len(data)):\n",
    "            flag = 0\n",
    "            for k in range(len(attributeCount)):\n",
    "                if (data[j][i]==attributeCount[k][0] and data[j][-1]==attributeCount[k][1] and i == attributeCount[k][2]):\n",
    "                    attributeCount[k][3] = attributeCount[k][3] + 1\n",
    "                    flag = 1\n",
    "                \n",
    "            if(flag == 0):\n",
    "                attributeCount.append([data[j][i], data[j][-1], i, 1])\n",
    "            \n",
    "            #if (data[j][i] not in attr):\n",
    "             #   if (len(attr)==0):\n",
    "              #      attributeCount.append([data[j][i], data[j][-1], 1])\n",
    "               # else:\n",
    "                #    for k in range(len(attributeCount)):\n",
    "                 #       if (data[j][i]==attributeCount[k][0] and data[j][-1]==attributeCount[k][1]):\n",
    "                  #          attributeCount[k][2] = attributeCount[k][2] + 1\n",
    "                #attr.append([data[j][i], data[j][-1]])\n",
    "\n",
    "    #euclidean\n",
    "    if (dataType == 0):\n",
    "        for i in range(len(data)):\n",
    "            distance = calcDistance(query, data[i], weighted)\n",
    "            distances.append((data[i], distance[0], distance[1]))\n",
    "        distances.sort(key=lambda x: x[0], reverse=True)\n",
    "        distances.sort(key=lambda x: x[1], reverse=False)\n",
    "    #vdm\n",
    "    elif (dataType == 1):\n",
    "        for i in range(len(data)):\n",
    "            distance = calcVDM(query, data[i], weighted, attributeCount, classList)\n",
    "            distances.append((data[i], distance[0], distance[1]))\n",
    "        distances.sort(key=lambda x: x[0], reverse=True)\n",
    "        distances.sort(key=lambda x: x[1], reverse=False)\n",
    "    \n",
    "    #hvdm\n",
    "    elif (dataType == 2):\n",
    "        for i in range(len(data)):\n",
    "            distance = calcHVDM(query, data[i], weighted, attributeCount, classList, typeList)\n",
    "            distances.append((data[i], distance[0], distance[1]))\n",
    "        distances.sort(key=lambda x: x[0], reverse=True)\n",
    "        distances.sort(key=lambda x: x[1], reverse=False)\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LVQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#criar X protótipos aleatórios(pelo menos 1 de cada classe)\n",
    "#varrer o dataset aleatoriamente N vezes\n",
    "    # achar o protótipo m mais próximo da instância x\n",
    "    # ajustar posição do protótipo m pela regra m' = m + w(t)*[pos(x)-pos(m)]\n",
    "        # w(t) 0.5 -> 0.01\n",
    "        \n",
    "#rodar knn no dataset dos protótipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createPrototypes(n, dataset, classes, mySeed):\n",
    "    prototypes = []\n",
    "    random.seed(mySeed)\n",
    "    for i in range(len(classes)):\n",
    "        myProt = []\n",
    "        for j in range(len(dataset.T)-1):\n",
    "            myMax = dataset.max()[j]\n",
    "            myMin = dataset.min()[j]\n",
    "            value = random.randint(myMin,myMax)\n",
    "            myProt.append(value)\n",
    "        myProt.append(classes[i])\n",
    "        prototypes.append(myProt)\n",
    "    \n",
    "    for i in range(n - len(classes)):\n",
    "        myProt = []\n",
    "        for j in range(len(dataset.T)-1):\n",
    "            myMax = dataset.max()[j]\n",
    "            myMin = dataset.min()[j]\n",
    "            value = random.randint(myMin,myMax)\n",
    "            myProt.append(value)\n",
    "        myClass = random.randint(0,(len(classes)-1))\n",
    "        myProt.append(classes[myClass])\n",
    "        prototypes.append(myProt)\n",
    "    \n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def protDists(instance, prototypes):\n",
    "    distances = []\n",
    "    for i in range(len(prototypes)):\n",
    "        dist = calcDistance(instance,prototypes[i],0)\n",
    "        distances.append([dist[0], i])\n",
    "    distances.sort(key=lambda x: x[0], reverse=False)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDiff(instance, prototype):\n",
    "    diff = []\n",
    "    for i in range(len(instance)-1):\n",
    "        diff.append(instance[i] - prototype[i])\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyDiff(prototype, diff, opp, alfa):\n",
    "    for i in range(len(prototype)-1):\n",
    "        if(opp == 1):\n",
    "            prototype[i] = prototype[i] + alfa*diff[i]\n",
    "        else:\n",
    "            prototype[i] = prototype[i] - alfa*diff[i]\n",
    "    return prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjustPrototypes(n, trainset, prototypes, mySeed):\n",
    "    random.seed(mySeed)\n",
    "    \n",
    "    alfa = 0.5\n",
    "    finalAlfa = 0.01\n",
    "    steps = len(trainset)*n\n",
    "    ratio = (alfa - finalAlfa)/steps\n",
    "    \n",
    "    for i in range (n):\n",
    "        for j in range(len(trainset)):\n",
    "            pos = random.randint(0,(len(trainset)-1))\n",
    "            closestProtPos = protDists(trainset.iloc[pos],prototypes)[0][1]\n",
    "            diff = getDiff(trainset.iloc[pos],prototypes[closestProtPos])\n",
    "\n",
    "            if (trainset.iloc[pos][-1] == prototypes[closestProtPos][-1]):\n",
    "                prototypes[closestProtPos] = applyDiff(prototypes[closestProtPos], diff, 1, alfa)\n",
    "            else:\n",
    "                prototypes[closestProtPos] = applyDiff(prototypes[closestProtPos], diff, 0, alfa)\n",
    "                \n",
    "            alfa = alfa - ratio\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Folds Cross-Validation\n",
    "### (Implementação usada na lista 01, mas usando os protótipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataretrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getClassList(dataset):\n",
    "    classes = []\n",
    "    for i in range(len(dataset)):\n",
    "        if (dataset.iloc[i][-1] not in classes):\n",
    "            classes.append(dataset.iloc[i][-1])\n",
    "            \n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kFolds (dataset, k, shuffle, mySeed):\n",
    "    \n",
    "    if (shuffle==1):\n",
    "        random.seed(mySeed)\n",
    "        finalDataset = dataset.sample(frac=1, random_state=mySeed)\n",
    "    else:\n",
    "        finalDataset = dataset.copy()\n",
    "        \n",
    "    splittedDataset = np.array_split(finalDataset, k)\n",
    "    \n",
    "    return splittedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossValidation(dataset, kFold, shuffle, mySeed, kVariation, weighted, dataType, typeList):\n",
    "    \n",
    "    foldHits = []\n",
    "    for i in range(len(kVariation)):\n",
    "        foldHits.append(0)\n",
    "        \n",
    "    datasetFolds = kFolds(dataset, kFold, shuffle, mySeed)\n",
    "    for i in range(kFold):\n",
    "        testset = datasetFolds[i].reset_index(drop=True)\n",
    "        frames = []\n",
    "        for j in range(kFold):\n",
    "            if (not j==i):\n",
    "                frames.append(datasetFolds[j])\n",
    "        trainset = pd.concat(frames).reset_index(drop=True)\n",
    "        hits = 0\n",
    "        trainsetList = trainset.values.tolist()\n",
    "        for m in range(len(testset)):\n",
    "            neighbors = knn(testset.iloc[m], trainsetList, weighted, dataType, typeList)\n",
    "            for z in range(len(kVariation)):\n",
    "                prediction = getNeighbors(neighbors, kVariation[z])    \n",
    "                if (prediction == testset.iloc[m][-1]):\n",
    "                    foldHits[z] = foldHits[z] + 1\n",
    "                \n",
    "    \n",
    "    for n in range(len(foldHits)):\n",
    "        foldHits[n] = foldHits[n]/len(dataset)    \n",
    "    return foldHits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossValidationPrototypes(dataset, kFold, shuffle, mySeed, kVariation, weighted, dataType, typeList, protQuant, iterations):\n",
    "    \n",
    "    classes = getClassList(dataset)\n",
    "    \n",
    "    foldHits = []\n",
    "    for i in range(len(kVariation)):\n",
    "        foldHits.append(0)\n",
    "        \n",
    "    datasetFolds = kFolds(dataset, kFold, shuffle, mySeed)\n",
    "    for i in range(kFold):\n",
    "        testset = datasetFolds[i].reset_index(drop=True)\n",
    "        frames = []\n",
    "        for j in range(kFold):\n",
    "            if (not j==i):\n",
    "                frames.append(datasetFolds[j])\n",
    "        trainset = pd.concat(frames).reset_index(drop=True)\n",
    "        \n",
    "        prototypes = createPrototypes(protQuant, trainset, classes, mySeed)\n",
    "        prototypes = adjustPrototypes(iterations, trainset, prototypes, mySeed)\n",
    "        \n",
    "        hits = 0\n",
    "        #trainsetList = trainset.values.tolist()\n",
    "        trainsetList = prototypes\n",
    "        \n",
    "        for m in range(len(testset)):\n",
    "            neighbors = knn(testset.iloc[m], trainsetList, weighted, dataType, typeList)\n",
    "            for z in range(len(kVariation)):\n",
    "                prediction = getNeighbors(neighbors, kVariation[z])    \n",
    "                if (prediction == testset.iloc[m][-1]):\n",
    "                    foldHits[z] = foldHits[z] + 1\n",
    "                \n",
    "    \n",
    "    for n in range(len(foldHits)):\n",
    "        foldHits[n] = foldHits[n]/len(dataset)    \n",
    "    return foldHits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataretrieve = pd.read_csv(\"..//datasets/dataretrieve.csv\", na_values='?')\n",
    "desharnais = pd.read_csv(\"..//datasets/desharnais.csv\", na_values='?')\n",
    "dataretrieve = dataretrieve.fillna(0)\n",
    "desharnais = desharnais.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"..//datasets/dataretrieve.txt\") as infile:\n",
    "    dataretrievelist = infile.read()\n",
    "    dataretrievelist = dataretrievelist.split(',')\n",
    "with open(\"..//datasets/desharnais.txt\") as infile:\n",
    "    desharnaislist = infile.read()\n",
    "    desharnaislist = desharnaislist.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo do Score\n",
    "### (Implementação usada na lista 01, sem medir o tempo e com uso de protótipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kVariation = [1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateScores(dataset, weighted, dataType, typeList):\n",
    "    scores = []\n",
    "    #startTime = time.time()\n",
    "    scores = crossValidation(dataset, 5, 1, 1000, kVariation, weighted, dataType, typeList)\n",
    "    #finishTime = time.time()\n",
    "    #totalTime = finishTime - startTime\n",
    "    return scores #[,totalTime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateScoresPrototypes(dataset, weighted, dataType, typeList, protQuant, iterations):\n",
    "    scores = crossValidationPrototypes(dataset, 5, 1, 1000, kVariation, weighted, dataType, typeList, protQuant, iterations)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados sem protótipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.915385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         k1        k3\n",
       "0  0.838462  0.915385"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataretrieveNoProt = calculateScores(dataretrieve, 0, 0, dataretrievelist)\n",
    "dataretrieveNoProtDF = pd.DataFrame([dataretrieveNoProt], columns = ([\"k1\", \"k3\"]))\n",
    "dataretrieveNoProtDF.to_csv(\"..//results/dataretrieveNoProt.csv\", index=False)\n",
    "dataretrieveNoProtDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         k1        k3\n",
       "0  0.530864  0.555556"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desharnaisNoProt = calculateScores(desharnais, 0, 0, desharnaislist)\n",
    "desharnaisNoProtDF = pd.DataFrame([desharnaisNoProt], columns = ([\"k1\", \"k3\"]))\n",
    "desharnaisNoProtDF.to_csv(\"..//results/desharnaisNoProt.csv\", index=False)\n",
    "desharnaisNoProtDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados com LVQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protótipos = nº de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-278-2d7610bc50b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataretrieveLVQ1Prot2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateScoresPrototypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataretrieve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataretrievelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetClassList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataretrieve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataretrieveLVQ1Prot2DF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataretrieveLVQ1Prot2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"k1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"k3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataretrieveLVQ1Prot2DF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..//results/dataretrieveLVQ1Prot2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataretrieveLVQ1Prot2DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-254-cbd19acb9916>\u001b[0m in \u001b[0;36mcalculateScoresPrototypes\u001b[0;34m(dataset, weighted, dataType, typeList, protQuant, iterations)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculateScoresPrototypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypeList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotQuant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossValidationPrototypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkVariation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypeList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotQuant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-258-ea829f7eb2f6>\u001b[0m in \u001b[0;36mcrossValidationPrototypes\u001b[0;34m(dataset, kFold, shuffle, mySeed, kVariation, weighted, dataType, typeList, protQuant, iterations)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainsetList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypeList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkVariation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkVariation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mfoldHits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfoldHits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-277-1a5f7e409f27>\u001b[0m in \u001b[0;36mgetNeighbors\u001b[0;34m(distances, n)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmyClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmyWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmyClass\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dataretrieveLVQ1Prot2 = calculateScoresPrototypes(dataretrieve, 0, 0, dataretrievelist, len(getClassList(dataretrieve)), 3)\n",
    "dataretrieveLVQ1Prot2DF = pd.DataFrame([dataretrieveLVQ1Prot2], columns = ([\"k1\", \"k3\"]))\n",
    "dataretrieveLVQ1Prot2DF.to_csv(\"..//results/dataretrieveLVQ1Prot2.csv\", index=False)\n",
    "dataretrieveLVQ1Prot2DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.567901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         k1        k3\n",
       "0  0.567901  0.567901"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desharnaisLVQ1Prot2 = calculateScoresPrototypes(desharnais, 0, 0, desharnaislist, len(getClassList(desharnais)), 3)\n",
    "desharnaisLVQ1Prot2DF = pd.DataFrame([desharnaisLVQ1Prot2], columns = ([\"k1\", \"k3\"]))\n",
    "desharnaisLVQ1Prot2DF.to_csv(\"..//results/desharnaisLVQ1Prot2.csv\", index=False)\n",
    "desharnaisLVQ1Prot2DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protótipos = nº de classes + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protótipos = 2x nº de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protótipos = 3x nº de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados com LVQ2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados com LVQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
